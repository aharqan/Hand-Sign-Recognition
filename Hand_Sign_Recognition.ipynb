{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand Sign Language Recognition using CNN\n",
    "### Practical Data Science Final Project by __Abdulaziz Al-Harqan and Aigerim Karatay__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction (Motivation)\n",
    "__Communication__ is central in how we live. \n",
    "\n",
    "However, communication can get difficult for mute people in their daily activities, even in such simple things as ordering food from the drivethrough restaurants. As most of us know, we communicate with the restaurant staff through the microphone at the drivethrough window. There is also a camera that is pretty much useless, but records you so that staff can see you while you speak. \n",
    "\n",
    "Mute people, however, cannot use the microphone, and camera cannot do mush as well as most of the staff do not know how to decode sign language. This obviously makes it harder for mute people because they have to type what they want to say everytime, or bring a human translator with them.\n",
    "\n",
    "Thus, we thought and asked: \"How can we understand and recognise the sign language with the help of computers?\", so that we can use the cameras to help mute people in the regards as described above. Therefore, we have decided to build the model that predicts sign language letters from the digital images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We have used __Sign Language MNIST__ dataset from Kaggle that contains he training data (27,455 cases) and test data (7172 cases). \n",
    "\n",
    "Each training and test case represents a label (0-24) as a one-to-one map for each alphabetic letter A-Z (and no cases for 9=J or 25=Z because those letters require motion and cannot be captured in an image). \n",
    "\n",
    "Dataset contains a header row of label, pixel1,pixel2….pixel784 which represent a single 28x28 pixel image with grayscale values between 0-255. The original hand gesture image data represented multiple users repeating the gesture against different backgrounds. \n",
    "\n",
    "The dataset can be accessed at: https://www.kaggle.com/datasets/datamunge/sign-language-mnist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the required libraries in a cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "#To split the data for the model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieving the training and testing data and saving them into dataframes called \"train\" and \"test\" accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../Project/Data/sign_mnist_train.csv\")\n",
    "test = pd.read_csv(\"../Project/Data/sign_mnist_test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what data train set contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>pixel11</th>\n",
       "      <th>pixel12</th>\n",
       "      <th>pixel13</th>\n",
       "      <th>pixel14</th>\n",
       "      <th>pixel15</th>\n",
       "      <th>pixel16</th>\n",
       "      <th>pixel17</th>\n",
       "      <th>pixel18</th>\n",
       "      <th>pixel19</th>\n",
       "      <th>pixel20</th>\n",
       "      <th>pixel21</th>\n",
       "      <th>pixel22</th>\n",
       "      <th>pixel23</th>\n",
       "      <th>pixel24</th>\n",
       "      <th>pixel25</th>\n",
       "      <th>pixel26</th>\n",
       "      <th>pixel27</th>\n",
       "      <th>pixel28</th>\n",
       "      <th>pixel29</th>\n",
       "      <th>pixel30</th>\n",
       "      <th>pixel31</th>\n",
       "      <th>pixel32</th>\n",
       "      <th>pixel33</th>\n",
       "      <th>pixel34</th>\n",
       "      <th>pixel35</th>\n",
       "      <th>pixel36</th>\n",
       "      <th>pixel37</th>\n",
       "      <th>pixel38</th>\n",
       "      <th>pixel39</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel745</th>\n",
       "      <th>pixel746</th>\n",
       "      <th>pixel747</th>\n",
       "      <th>pixel748</th>\n",
       "      <th>pixel749</th>\n",
       "      <th>pixel750</th>\n",
       "      <th>pixel751</th>\n",
       "      <th>pixel752</th>\n",
       "      <th>pixel753</th>\n",
       "      <th>pixel754</th>\n",
       "      <th>pixel755</th>\n",
       "      <th>pixel756</th>\n",
       "      <th>pixel757</th>\n",
       "      <th>pixel758</th>\n",
       "      <th>pixel759</th>\n",
       "      <th>pixel760</th>\n",
       "      <th>pixel761</th>\n",
       "      <th>pixel762</th>\n",
       "      <th>pixel763</th>\n",
       "      <th>pixel764</th>\n",
       "      <th>pixel765</th>\n",
       "      <th>pixel766</th>\n",
       "      <th>pixel767</th>\n",
       "      <th>pixel768</th>\n",
       "      <th>pixel769</th>\n",
       "      <th>pixel770</th>\n",
       "      <th>pixel771</th>\n",
       "      <th>pixel772</th>\n",
       "      <th>pixel773</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>160</td>\n",
       "      <td>163</td>\n",
       "      <td>165</td>\n",
       "      <td>159</td>\n",
       "      <td>166</td>\n",
       "      <td>168</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>172</td>\n",
       "      <td>171</td>\n",
       "      <td>171</td>\n",
       "      <td>170</td>\n",
       "      <td>170</td>\n",
       "      <td>169</td>\n",
       "      <td>111</td>\n",
       "      <td>121</td>\n",
       "      <td>129</td>\n",
       "      <td>135</td>\n",
       "      <td>141</td>\n",
       "      <td>144</td>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>154</td>\n",
       "      <td>157</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>205</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>205</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "      <td>142</td>\n",
       "      <td>151</td>\n",
       "      <td>160</td>\n",
       "      <td>172</td>\n",
       "      <td>196</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>190</td>\n",
       "      <td>135</td>\n",
       "      <td>96</td>\n",
       "      <td>86</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>79</td>\n",
       "      <td>176</td>\n",
       "      <td>205</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>156</td>\n",
       "      <td>154</td>\n",
       "      <td>154</td>\n",
       "      <td>153</td>\n",
       "      <td>152</td>\n",
       "      <td>151</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>148</td>\n",
       "      <td>147</td>\n",
       "      <td>146</td>\n",
       "      <td>144</td>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>138</td>\n",
       "      <td>92</td>\n",
       "      <td>108</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>159</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>160</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>78</td>\n",
       "      <td>120</td>\n",
       "      <td>157</td>\n",
       "      <td>168</td>\n",
       "      <td>107</td>\n",
       "      <td>99</td>\n",
       "      <td>121</td>\n",
       "      <td>133</td>\n",
       "      <td>97</td>\n",
       "      <td>95</td>\n",
       "      <td>120</td>\n",
       "      <td>135</td>\n",
       "      <td>116</td>\n",
       "      <td>95</td>\n",
       "      <td>79</td>\n",
       "      <td>69</td>\n",
       "      <td>86</td>\n",
       "      <td>139</td>\n",
       "      <td>173</td>\n",
       "      <td>200</td>\n",
       "      <td>185</td>\n",
       "      <td>175</td>\n",
       "      <td>198</td>\n",
       "      <td>124</td>\n",
       "      <td>118</td>\n",
       "      <td>94</td>\n",
       "      <td>140</td>\n",
       "      <td>133</td>\n",
       "      <td>84</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>185</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>179</td>\n",
       "      <td>178</td>\n",
       "      <td>178</td>\n",
       "      <td>109</td>\n",
       "      <td>52</td>\n",
       "      <td>66</td>\n",
       "      <td>77</td>\n",
       "      <td>83</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>203</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>196</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>193</td>\n",
       "      <td>198</td>\n",
       "      <td>166</td>\n",
       "      <td>132</td>\n",
       "      <td>114</td>\n",
       "      <td>89</td>\n",
       "      <td>74</td>\n",
       "      <td>79</td>\n",
       "      <td>77</td>\n",
       "      <td>74</td>\n",
       "      <td>78</td>\n",
       "      <td>132</td>\n",
       "      <td>188</td>\n",
       "      <td>210</td>\n",
       "      <td>209</td>\n",
       "      <td>206</td>\n",
       "      <td>205</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>209</td>\n",
       "      <td>207</td>\n",
       "      <td>208</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>198</td>\n",
       "      <td>197</td>\n",
       "      <td>195</td>\n",
       "      <td>192</td>\n",
       "      <td>197</td>\n",
       "      <td>171</td>\n",
       "      <td>51</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>215</td>\n",
       "      <td>215</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>213</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>...</td>\n",
       "      <td>247</td>\n",
       "      <td>242</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>229</td>\n",
       "      <td>227</td>\n",
       "      <td>225</td>\n",
       "      <td>223</td>\n",
       "      <td>221</td>\n",
       "      <td>220</td>\n",
       "      <td>216</td>\n",
       "      <td>58</td>\n",
       "      <td>51</td>\n",
       "      <td>49</td>\n",
       "      <td>50</td>\n",
       "      <td>57</td>\n",
       "      <td>60</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>159</td>\n",
       "      <td>255</td>\n",
       "      <td>237</td>\n",
       "      <td>239</td>\n",
       "      <td>237</td>\n",
       "      <td>236</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>187</td>\n",
       "      <td>190</td>\n",
       "      <td>192</td>\n",
       "      <td>193</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>194</td>\n",
       "      <td>194</td>\n",
       "      <td>166</td>\n",
       "      <td>169</td>\n",
       "      <td>172</td>\n",
       "      <td>174</td>\n",
       "      <td>177</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>90</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>117</td>\n",
       "      <td>123</td>\n",
       "      <td>127</td>\n",
       "      <td>129</td>\n",
       "      <td>134</td>\n",
       "      <td>145</td>\n",
       "      <td>152</td>\n",
       "      <td>156</td>\n",
       "      <td>179</td>\n",
       "      <td>105</td>\n",
       "      <td>106</td>\n",
       "      <td>105</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>104</td>\n",
       "      <td>175</td>\n",
       "      <td>199</td>\n",
       "      <td>178</td>\n",
       "      <td>152</td>\n",
       "      <td>136</td>\n",
       "      <td>130</td>\n",
       "      <td>136</td>\n",
       "      <td>150</td>\n",
       "      <td>118</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>76</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
       "0      3     107     118     127  ...       206       204       203       202\n",
       "1      6     155     157     156  ...       175       103       135       149\n",
       "2      2     187     188     188  ...       198       195       194       195\n",
       "3      2     211     211     212  ...       225       222       229       163\n",
       "4     13     164     167     170  ...       157       163       164       179\n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what shape the train set has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27455, 785)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check what shape the test set has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172, 785)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's explore what are the contents of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels, as we can see below, are represented by numbers from 0 to 24, where A is represented as 0, B as 1, C as 2, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3,  6,  2, ..., 18, 17, 23])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = train.label.values\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "Now let's analyze the data as a whole picture. We start from plotting the data as a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (10,5))\n",
    "sns.countplot(x = train_labels, color = \"skyblue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can interpret that letters are almost equally distributed, all letters betwenn 1000 and 1200 instances in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue that must be dealt with is labels representation. Since values are represented in numbers (from 0 to 23), higher numbers will be given higher values. This is not desirable, thus we decided to one-hot-encode the labels for the accurate processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_binrizer = LabelBinarizer()\n",
    "binary_labels = label_binrizer.fit_transform(train_labels)\n",
    "binary_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the labels are converted into a one-hot-encoded array, we no longer need the 'label' column in the dataframe, so we drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('label', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataframe into an array of images in the form of list. Each element is an image representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train.values\n",
    "train_images = np.array([np.reshape(i, (28, 28)) for i in train_images])\n",
    "train_images = np.array([i.flatten() for i in train_images])\n",
    "#images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets display some examples of the images array, for example the one below is \"C\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7b6decc2b0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This is a letter \"C\"\n",
    "plt.imshow(train_images[2].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And another one is \"S\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7b6dde8bb0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This is the letter \"S\"\n",
    "plt.imshow(train_images[10].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "### CNN to Process Images and Create a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using Convolutional Neural Networks (CNN) to train the Model. \n",
    "\n",
    "CNNs, similar to neural networks, are made up of \"neurons\" with learnable weights and biases. Each \"neuron\" receives several inputs, takes a weighted sum over them, pass it through an activation function and responds with an output.\n",
    "\n",
    "Check more about CNN at https://towardsdatascience.com/coding-a-convolutional-neural-network-cnn-using-keras-sequential-api-ec5211126875. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start from splitting the training data into: Training Set (80%) and Validation Set (20%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__train_images__: an array of lists, each element is a row represented as a list of pixels. Thus, we have a 28x28 representation of images instead of a single long list of 784 elements.\n",
    "\n",
    "__binary_labels__: is the one-hot-encoding representation of letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_vald, y_train, y_vald = train_test_split(train_images, binary_labels, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Since all the values in the dataframe are pixels ranging from 0-255, we can normalize the value for better performance and ease of processing. We divide all the values by 255, to have the pixels ranging from 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_vald = x_vald / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After normalizing the values, we can reshape the array into a Matrix, each element is a row represented as a list of pixels. Thus, we have a 28x28 representation of images instead of a single long list of 784 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_vald = x_vald.reshape(x_vald.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model\n",
    "Now we can create the model layers to start the training process.\n",
    "\n",
    "A convolutional neural network (CNN) consists of an input and an output layer, as well as multiple hidden layers.\n",
    "The hidden layers of a CNN typically consist of a series of convolutional layers that convolve with a multiplication or other dot product.\n",
    "\n",
    "The activation function is commonly a RELU layer, and is subsequently followed by additional convolutions such as pooling layers, fully connected layers and normalization layers, referred to as hidden layers because their inputs and outputs are masked by the activation function and final convolution.\n",
    "\n",
    "Check more about CNN layers at: https://www.kaggle.com/code/prashant111/comprehensive-guide-to-cnn-with-keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN model below is retrieved from: https://towardsdatascience.com/using-convolutional-neural-network-for-image-classification-5997bfd0ede4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation = 'relu', input_shape=(28, 28 ,1) ))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.20))\n",
    "#24 because we have a total of 24 classes \n",
    "#(letters ranging from A-Y. Excluding J and Z since they're not in the dataset)\n",
    "model.add(Dense(24, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building the model layers we need to compile it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss = \"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.compile(loss = keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the model that has been compiled by looking at its summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 13, 13, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 1, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 24)                3096      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 85,912\n",
      "Trainable params: 85,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now its time to start training the model. To avoid overfitting, we decided to use __EarlyStoppping__ feature. EarlyStopping stops the training when a monitored metric has stopped improving.\n",
    "\n",
    "As the goal of our training is to minimize the loss, the metric to be monitored would be 'loss', and mode would be 'min'. \n",
    "\n",
    "At the end of every epoch __model.fit()__ training loop will check whether the loss is no longer decreasing. Once it has found that loss is no longer decreasing, model.stop_training is marked True and the training terminates.\n",
    "\n",
    "Check more details about EarlyStopping at https://keras.io/api/callbacks/early_stopping/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 2.7505 - accuracy: 0.1665 - val_loss: 1.9378 - val_accuracy: 0.3968\n",
      "Epoch 2/40\n",
      "110/110 [==============================] - 11s 97ms/step - loss: 1.4343 - accuracy: 0.5298 - val_loss: 0.9180 - val_accuracy: 0.7223\n",
      "Epoch 3/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.8327 - accuracy: 0.7220 - val_loss: 0.5739 - val_accuracy: 0.8175\n",
      "Epoch 4/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.5520 - accuracy: 0.8111 - val_loss: 0.3853 - val_accuracy: 0.8743\n",
      "Epoch 5/40\n",
      "110/110 [==============================] - 9s 86ms/step - loss: 0.3904 - accuracy: 0.8662 - val_loss: 0.2405 - val_accuracy: 0.9253\n",
      "Epoch 6/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.2650 - accuracy: 0.9142 - val_loss: 0.1671 - val_accuracy: 0.9547\n",
      "Epoch 7/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.1860 - accuracy: 0.9411 - val_loss: 0.1133 - val_accuracy: 0.9700\n",
      "Epoch 8/40\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.1346 - accuracy: 0.9588 - val_loss: 0.0605 - val_accuracy: 0.9913\n",
      "Epoch 9/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.1060 - accuracy: 0.9683 - val_loss: 0.0463 - val_accuracy: 0.9954\n",
      "Epoch 10/40\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.0740 - accuracy: 0.9801 - val_loss: 0.0310 - val_accuracy: 0.9960\n",
      "Epoch 11/40\n",
      "110/110 [==============================] - 10s 89ms/step - loss: 0.0597 - accuracy: 0.9840 - val_loss: 0.0200 - val_accuracy: 0.9976\n",
      "Epoch 12/40\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.0472 - accuracy: 0.9879 - val_loss: 0.0142 - val_accuracy: 0.9993\n",
      "Epoch 13/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0384 - accuracy: 0.9905 - val_loss: 0.0203 - val_accuracy: 0.9965\n",
      "Epoch 14/40\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.0329 - accuracy: 0.9916 - val_loss: 0.0121 - val_accuracy: 0.9985\n",
      "Epoch 15/40\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.0265 - accuracy: 0.9940 - val_loss: 0.0094 - val_accuracy: 0.9987\n",
      "Epoch 16/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0251 - accuracy: 0.9939 - val_loss: 0.0113 - val_accuracy: 0.9980\n",
      "Epoch 17/40\n",
      "110/110 [==============================] - 10s 94ms/step - loss: 0.0218 - accuracy: 0.9945 - val_loss: 0.0065 - val_accuracy: 0.9996\n",
      "Epoch 18/40\n",
      "110/110 [==============================] - 10s 89ms/step - loss: 0.0168 - accuracy: 0.9959 - val_loss: 0.0050 - val_accuracy: 0.9993\n",
      "Epoch 19/40\n",
      "110/110 [==============================] - 9s 85ms/step - loss: 0.0180 - accuracy: 0.9955 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 20/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0168 - accuracy: 0.9958 - val_loss: 0.0054 - val_accuracy: 0.9987\n",
      "Epoch 21/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.0034 - val_accuracy: 0.9998\n",
      "Epoch 22/40\n",
      "110/110 [==============================] - 9s 86ms/step - loss: 0.0104 - accuracy: 0.9977 - val_loss: 0.0036 - val_accuracy: 0.9995\n",
      "Epoch 23/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 24/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
      "Epoch 25/40\n",
      "110/110 [==============================] - 9s 86ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.0040 - val_accuracy: 0.9987\n",
      "Epoch 26/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0088 - accuracy: 0.9981 - val_loss: 0.0028 - val_accuracy: 0.9995\n",
      "Epoch 27/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 9.0305e-04 - val_accuracy: 1.0000\n",
      "Epoch 28/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0021 - val_accuracy: 0.9993\n",
      "Epoch 29/40\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.0066 - val_accuracy: 0.9976\n",
      "Epoch 30/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.0029 - val_accuracy: 0.9998\n",
      "Epoch 31/40\n",
      "110/110 [==============================] - 9s 86ms/step - loss: 0.0098 - accuracy: 0.9974 - val_loss: 0.0020 - val_accuracy: 0.9995\n",
      "Epoch 32/40\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 5.0472e-04 - val_accuracy: 1.0000\n",
      "Epoch 33/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0015 - val_accuracy: 0.9995\n",
      "Epoch 34/40\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.0062 - accuracy: 0.9985 - val_loss: 0.0020 - val_accuracy: 0.9998\n",
      "Epoch 35/40\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 3.8594e-04 - val_accuracy: 1.0000\n",
      "Epoch 36/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0049 - accuracy: 0.9988 - val_loss: 0.0013 - val_accuracy: 0.9998\n",
      "Epoch 37/40\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.0098 - accuracy: 0.9972 - val_loss: 0.0048 - val_accuracy: 0.9991\n",
      "Epoch 38/40\n",
      "110/110 [==============================] - 10s 87ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "Epoch 39/40\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0016 - val_accuracy: 0.9998\n",
      "Epoch 40/40\n",
      "110/110 [==============================] - 10s 88ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 3.0566e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 40, \n",
    "                    validation_data = (x_vald, y_vald), batch_size = 200, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform the same operations on the testing set as we did on the training set.\n",
    "\n",
    "__Operations are:__\n",
    "- Store the labels in a variable.\n",
    "- Drop 'label' column from the testing set dataframe.\n",
    "- Create an array that holds all the images (28x28).\n",
    "- One hot encoding the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test['label']\n",
    "test.drop('label', axis = 1, inplace = True)\n",
    "test_images = test.values\n",
    "#Reshaping each image(row) to 28x28\n",
    "test_images = np.array([np.reshape(i, (28, 28)) for i in test_images])\n",
    "test_images = np.array([i.flatten() for i in test_images])\n",
    "test_labels = label_binrizer.fit_transform(test_labels)\n",
    "#Reshaping \n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "#print(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how many instances in the testing set there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7172"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172, 24)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "After transforming the testing data to match the training data, we can predict the labels (letters) for the testing images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7172, 24)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(test_images)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compare the actual labels with the predicted ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8476017847183491"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_labels, y_pred.round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model's accuracy is around 84.7%, which is decent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "The accuracy of our model's prediction is decent, however...\n",
    "The model is limited in scope. It can only predict the sign language letter by letter, but our initial task was to convert the whole speech of mute people into digital sentences in real time. This requires more work put into the model. But as our model can do fundamental prediction, we hope that we can build more complex model in the future that can read letters in real time and convert them to full words and sentences. We also need to work on the prediction accuracy to make it a bit better that it currently is. \n",
    "\n",
    "Overall, we hope that our project idea might bring social benefit to the mute people to make their daily lives easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "Sign Language MNIST Dataset: https://www.kaggle.com/datasets/datamunge/sign-language-mnist\n",
    "\n",
    "About CNN: https://towardsdatascience.com/coding-a-convolutional-neural-network-cnn-using-keras-sequential-api-ec5211126875\n",
    "\n",
    "CNN with Keras: https://www.kaggle.com/code/prashant111/comprehensive-guide-to-cnn-with-keras \n",
    "\n",
    "Retreived CNN model: https://towardsdatascience.com/using-convolutional-neural-network-for-image-classification-5997bfd0ede4\n",
    "\n",
    "EarlyStopping feature in Keras: https://keras.io/api/callbacks/early_stopping/ \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7fe6d9e1369c96f0677f81f9d5dfea4dab8ec90eb65fb35cf46ecbc509bd6a73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
